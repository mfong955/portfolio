---
layout: default
title: AI Tools | Matthew Fong
description: AI-powered documentation tools built at AWS using Claude, MCP, and Python to streamline technical writing workflows.
---

<section class="page-hero">
  <div class="page-hero-content">
    <h1>AI Tools for Documentation</h1>
    <p class="lead">
      Custom AI-powered workflows I designed and built at AWS to streamline documentation
      processes—demonstrating hands-on experience with LLMs, prompt engineering, and
      automation pipelines.
    </p>
  </div>
</section>

<article class="page-content">
  <div class="sample-meta">
    <div class="meta-item">
      <span class="meta-label">Built with:</span>
      <span>Claude, MCP Protocol, Python</span>
    </div>
    <div class="meta-item">
      <span class="meta-label">Context:</span>
      <span>Internal AWS Tools</span>
    </div>
    <div class="meta-item">
      <span class="meta-label">Impact:</span>
      <span>30%+ time savings, 80%+ adoption</span>
    </div>
  </div>

  <nav class="page-toc">
    <h4>On This Page</h4>
    <ul>
      <li><a href="#context">About These Tools</a></li>
      <li><a href="#drafting-pipeline">Documentation Drafting Pipeline</a></li>
      <li><a href="#ticket-workflow">Ticket Resolution Workflow</a></li>
      <li><a href="#promotion-assistant">Promotion Documentation Assistant</a></li>
      <li><a href="#training">AI Training Courses</a></li>
      <li><a href="#skills">Technical Skills Demonstrated</a></li>
    </ul>
  </nav>

  <h2 id="context">About These Tools</h2>
  <p>
    At AWS, I didn't just write documentation—I built AI systems to make documentation
    workflows faster and more consistent. These tools were developed for internal use and
    deployed across the SageMaker AI documentation team.
  </p>

  <div class="info-box">
    <h4>A Note on Samples</h4>
    <p>
      These tools were built for internal AWS workflows and are not available for external
      demonstration. What I can share is how they worked, the problems they solved, and the
      measurable impact they had. The experience I gained building these systems has only
      deepened since—I continue to explore and build with new AI capabilities as they emerge.
    </p>
  </div>

  <h2 id="drafting-pipeline">Documentation Drafting Pipeline</h2>
  <div class="info-box highlight">
    <h4>Problem Solved</h4>
    <p>
      Technical writers spend significant time transforming raw technical inputs (PRFAQs,
      design documents, API specifications) into customer-facing documentation. This process
      involves understanding context, applying style guidelines, and multiple revision cycles.
    </p>
  </div>

  <h3>How It Worked</h3>
  <p>
    I built a multi-stage AI pipeline using Claude and MCP (Model Context Protocol) that
    automated the initial drafting process:
  </p>
  <ul>
    <li><strong>Context ingestion:</strong> System reads and understands source documents
    (PRFAQs, engineering specs, API references)</li>
    <li><strong>Structured output:</strong> Generates documentation following our team's
    information architecture and style guidelines</li>
    <li><strong>Fact-checking layer:</strong> Cross-references generated content against
    source documents to catch hallucinations</li>
    <li><strong>Editorial review:</strong> Applies style guide rules and flags potential
    issues for human review</li>
    <li><strong>Feedback integration:</strong> Incorporates reviewer comments and learns
    from corrections</li>
  </ul>

  <h3>Results</h3>
  <ul>
    <li><strong>30%+ reduction</strong> in time from initial draft to review-ready content</li>
    <li>Consistent application of style guidelines across all generated content</li>
    <li>Reduced cognitive load on writers, allowing focus on technical accuracy and user needs</li>
  </ul>

  <h2 id="ticket-workflow">Ticket Resolution Workflow</h2>
  <div class="info-box highlight">
    <h4>Problem Solved</h4>
    <p>
      Documentation tickets often require repetitive analysis: understanding the request,
      locating relevant source files, determining the appropriate fix, and implementing
      changes. This manual process created bottlenecks.
    </p>
  </div>

  <h3>How It Worked</h3>
  <p>
    I developed an agentic system that automated ticket analysis and resolution:
  </p>
  <ul>
    <li><strong>Ticket parsing:</strong> Takes ticket URL as input, extracts requirements
    and context</li>
    <li><strong>Codebase navigation:</strong> Automatically locates relevant XML source
    files in the documentation repository</li>
    <li><strong>Action planning:</strong> Breaks down the ticket into discrete steps with
    clear acceptance criteria</li>
    <li><strong>Multiple output modes:</strong> Can generate diff-style changes, direct
    XML updates, or flagged sections for human review</li>
    <li><strong>Searchable flags:</strong> Inserts markers in output for easy location
    of changes requiring attention</li>
  </ul>

  <h3>Results</h3>
  <ul>
    <li>Reduced routine ticket resolution time significantly</li>
    <li>Standardized approach to common documentation fixes</li>
    <li>Freed up writer time for more complex, high-value work</li>
  </ul>

  <h2 id="promotion-assistant">Promotion Documentation Assistant</h2>
  <div class="info-box highlight">
    <h4>Problem Solved</h4>
    <p>
      Performance review and promotion documentation requires synthesizing months of
      accomplishments into structured narratives—a time-consuming process that most
      people dread.
    </p>
  </div>

  <h3>How It Worked</h3>
  <p>
    A personal productivity tool I built to streamline my own promotion preparation:
  </p>
  <ul>
    <li><strong>Accomplishment ingestion:</strong> Accepts unstructured notes, bullet
    points, and raw accomplishment data</li>
    <li><strong>Format knowledge:</strong> Understands promotion document structures
    and evaluation criteria</li>
    <li><strong>Narrative generation:</strong> Transforms raw inputs into structured
    stories with clear impact statements</li>
    <li><strong>STAR format:</strong> Automatically structures content into Situation,
    Task, Action, Result format</li>
  </ul>

  <h2 id="training">AI Training Courses</h2>
  <p>
    Beyond building tools, I created and taught AI training courses for AWS employees:
  </p>
  <ul>
    <li><strong>Prompt engineering fundamentals:</strong> How to write effective prompts
    for documentation tasks</li>
    <li><strong>Tool development:</strong> Building custom AI workflows for specific
    use cases</li>
    <li><strong>Best practices:</strong> Quality control, fact-checking, and maintaining
    accuracy when using AI assistance</li>
  </ul>

  <div class="info-box success">
    <h4>Training Impact</h4>
    <p>
      Post-course surveys showed <strong>80%+ adoption rates</strong> of the techniques
      taught, with participants reporting <strong>30%+ productivity gains</strong> in
      their documentation workflows.
    </p>
  </div>

  <h2 id="skills">Technical Skills Demonstrated</h2>
  <p>Building these tools required combining multiple skill sets:</p>
  <ul>
    <li><strong>LLM Integration:</strong> Claude API, prompt engineering, context management</li>
    <li><strong>MCP Protocol:</strong> Building tools that extend Claude's capabilities</li>
    <li><strong>Python Development:</strong> Automation scripts, API integrations, file processing</li>
    <li><strong>Workflow Design:</strong> Multi-stage pipelines with error handling and human-in-the-loop checkpoints</li>
    <li><strong>Documentation Domain Knowledge:</strong> Understanding what makes good documentation to train systems effectively</li>
  </ul>

  <div class="info-box">
    <h4>Continuing to Build</h4>
    <p>
      The AI landscape evolves rapidly, and so does my toolkit. I continue to experiment
      with new capabilities—from improved reasoning models to multi-agent architectures—
      always looking for ways to make documentation workflows more efficient and effective.
    </p>
  </div>
</article>
