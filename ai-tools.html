---
layout: default
title: AI/ML Engineering | Matthew Fong
description: AI-powered tools and systems built at AWS using Claude, MCP Protocol, and Python — from multi-stage drafting pipelines to agentic ticket resolution systems.
---

<section class="page-hero">
  <div class="page-hero-content">
    <h1>AI/ML Engineering Projects</h1>
    <p class="lead">
      Custom AI-powered tools and systems I designed and built at AWS&mdash;demonstrating
      hands-on LLM integration, prompt engineering, agentic architectures, and
      automation pipelines.
    </p>
  </div>
</section>

<article class="page-content">
  <div class="sample-meta">
    <div class="meta-item">
      <span class="meta-label">Built with:</span>
      <span>Claude, LLMs, AI, MCP Protocol, Python</span>
    </div>
    <div class="meta-item">
      <span class="meta-label">Context:</span>
      <span>Internal AWS Engineering</span>
    </div>
    <div class="meta-item">
      <span class="meta-label">Impact:</span>
      <span>Measurable workflow efficiency gains, freeing up time for strategic work</span>
    </div>
  </div>

  <h2 id="context">About These Projects</h2>
  <p>
    At AWS, I designed and built AI-powered systems that automated complex workflows,
    achieving measurable productivity gains. These tools were developed for internal use
    and some were shared across the organization.
  </p>

  <div class="info-box">
    <h4>A Note on Samples</h4>
    <p>
      These tools were built for internal AWS workflows and are not available for external
      demonstration. What I can share is how they worked, the problems they solved, and the
      measurable impact they had. The experience I gained building these systems has only
      deepened since—I continue to explore and build with new AI capabilities as they emerge.
    </p>
  </div>

  <h2 id="drafting-pipeline">Multi-Stage AI Drafting Pipeline</h2>
  <div class="info-box highlight">
    <h4>Problem Solved</h4>
    <p>
      Technical writers spend significant time transforming raw technical inputs (PRFAQs,
      design documents, API specifications) into customer-facing documentation. This process
      involves understanding context, applying style guidelines, and multiple revision cycles.
    </p>
  </div>

  <h3>How It Worked</h3>
  <p>
    I built a multi-stage AI pipeline using Amazon Q, LLMs, and MCP (Model Context Protocol) that
    automated the drafting process from initial draft through post-review revisions:
  </p>
  <ul>
    <li><strong>Context ingestion:</strong> System reads and understands source documents
    (PRFAQs, engineering specs, API references, etc.)</li>
    <li><strong>Fact-checking layer:</strong> Cross-references generated content against
    source documents to catch hallucinations</li>
    <li><strong>Editorial review:</strong> Applies top AWS style guide rules and flags potential
    issues for human review</li>
    <li><strong>Feedback integration (Quip):</strong> Writes to Quip, and after review,
      incorporates reviewer comments, learns from corrections, and creates new drafts with comment references</li>
    <li><strong>Structured output (XML):</strong> Generates documentation following AWS's
    information architecture, style guidelines, and formatting</li>
  </ul>

  <h3>Results</h3>
  <ul>
    <li>Reduction in time from initial draft to review-ready content and post-review draft</li>
    <li>Consistent application of style guidelines across all generated content</li>
    <li>Reduced cognitive load on writers, allowing more time to focus on technical accuracy and user needs</li>
  </ul>

  <h2 id="ticket-workflow">Agentic Ticket Resolution System</h2>
  <div class="info-box highlight">
    <h4>Problem Solved</h4>
    <p>
      Documentation tickets often require repetitive analysis: understanding the request,
      locating relevant source files, determining the appropriate fix, and implementing
      changes. This manual process created bottlenecks.
    </p>
  </div>

  <h3>How It Worked</h3>
  <p>
    I developed an agentic system that automated ticket analysis and resolution:
  </p>
  <ul>
    <li><strong>Ticket parsing:</strong> Takes ticket URL as input, extracts requirements
    and context</li>
    <li><strong>Codebase navigation:</strong> Automatically locates relevant XML source
    files in the documentation repository</li>
    <li><strong>Action planning:</strong> Breaks down the ticket into discrete steps with
    clear acceptance criteria, balancing short-term fixes and longer-term impact</li>
    <li><strong>Multiple output modes:</strong> Can generate diff-style changes, direct
    source XML updates, or flagged sections for human review</li>
    <li><strong>Searchable flags:</strong> Inserts markers in output for easy location
    of changes requiring attention</li>
  </ul>

  <h3>Results</h3>
  <ul>
    <li>Reduced routine simple ticket resolution time significantly</li>
    <li>Helped identify longer-term underlying documentation issues</li>
    <li>Standardized approach to common documentation fixes</li>
    <li>Freed up writer time for more complex, high-value work</li>
  </ul>

  <h2 id="promotion-assistant">Promotion Documentation Assistant</h2>
  <div class="info-box highlight">
    <h4>Problem Solved</h4>
    <p>
      Performance review and promotion documentation requires synthesizing months of
      accomplishments into structured narratives—a deeply time-consuming process.
    </p>
  </div>

  <h3>How It Worked</h3>
  <p>
    A personal productivity tool I built to streamline my own promotion preparation:
  </p>
  <ul>
    <li><strong>Accomplishment ingestion:</strong> Accepts unstructured notes, bullet
    points, and raw accomplishment data</li>
    <li><strong>Format knowledge:</strong> Uses company's promotion documents
    and evaluation criteria</li>
    <li><strong>Narrative generation:</strong> Transforms raw inputs into structured
    stories with clear impact statements</li>
    <li><strong>STAR format:</strong> Automatically structures content into Situation,
    Task, Action, Result format</li>
  </ul>

  <h2 id="training">AI Training Courses</h2>
  <p>
    Beyond building tools, I created and taught AI training courses for AWS employees
    for major AI initiatives:
  </p>
  <ul>
    <li><strong>Prompt engineering fundamentals:</strong> How to write effective prompts
    for documentation tasks and when and how to implement RAG</li>
    <li><strong>Tool development:</strong> Building custom AI workflows for specific
    use cases</li>
    <li><strong>Best practices:</strong> Quality control, fact-checking, and maintaining
    accuracy when using AI assistance</li>
  </ul>

  <div class="info-box success">
    <h4>Training Impact</h4>
    <p>
      Post-course surveys showed <strong>80%+ adoption rates</strong> of the techniques
      taught, with participants reporting <strong>30%+ productivity gains</strong> in
      their documentation workflows.
    </p>
  </div>

  <h2 id="skills">Technical Skills Demonstrated</h2>
  <p>Building these tools required combining multiple skill sets:</p>
  <ul>
    <li><strong>LLM Integration:</strong> Which foundation models for which purposes, prompt engineering, context management</li>
    <li><strong>MCP Protocol:</strong> Using tools that extend LLM capabilities</li>
    <li><strong>Python Development:</strong> Automation scripts, API integrations, file processing</li>
    <li><strong>Workflow Design:</strong> Multi-stage pipelines with error handling and human-in-the-loop checkpoints</li>
    <li><strong>Domain Expertise:</strong> Understanding end-user needs and content quality standards to design effective AI-assisted workflows</li>
  </ul>

  <div class="info-box">
    <h4>Continuing to Build</h4>
    <p>
      The AI landscape evolves rapidly, and so does my toolkit. I continue to experiment
      with new capabilities—from improved reasoning models to multi-agent architectures—
      always looking for ways to make knowledge workflows more efficient and effective.
    </p>
  </div>
</article>
